# Implementation of A3C(Asynchronous Advantage Actor-Critic)

* Asynchronous Advantage Actor-Critic()
* Tensorflow Implementation
* With one hour training gif

<div align="center">
  <img src="source/openaigym.video.0.21278.video000125.gif" width="50%" height='300'>
</div>

<div align="center">
  <img src="source/entropy.png" width="33%" height='300'>
  <img src="source/episode_step.png" width="33%" height='300'><img src="source/max_prob.png" width="33%" height='300'><img src="source/pi_loss.png" width="33%" height='300'><img src="source/reward.png" width="33%" height='300'><img src="source/value_loss.png" width="33%" height='300'>
</div>



# Reference

* [Asynchronous Advantage Actor-Critic](https://arxiv.org/abs/1602.01783)
* [https://github.com/kkweon/A3C-Tensorflow](https://github.com/kkweon/A3C-Tensorflow)
* [https://github.com/rlcode/reinforcement-learning-kr](https://github.com/rlcode/reinforcement-learning-kr)